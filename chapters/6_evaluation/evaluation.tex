\chapter{Evaluation}


% [Last chapter]


% [This chapter: Describe shortly all sections from this chapter]


% [In the next chapter]



% [Tools]

% python
% Matplotlib
% seaborn library
% source code for creating plots is here: 


% https://hpbn.co/primer-on-web-performance/#analyzing-real-user-measurement-data


% -------------------------------------------------------------


\section{Data Visualization and Interpretation}



% -------------------------------------------------------------


\subsection{Original Website vs Test Website without GA}

% how "good" is the mock?

%TODO add page weight

\begin{figure}
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{plots/original_vs_test/plt_fv.pdf}
		%\caption{A subfigure}
		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{plots/original_vs_test/plt_rv.pdf}
		%\caption{A subfigure}
		\label{fig:sub2}
	\end{subfigure}
	\caption{Page Load Time. First and Repeat View.}
	\label{figure:plt_original_test}
\end{figure}

Figure \ref{figure:plt_original_test}:
FV: very similar, original has less distribution
RV: test slightly faster, difference in median is 595 ms 


\begin{figure}
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{plots/original_vs_test/fcp_fv.pdf}
		%\caption{A subfigure}
		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{plots/original_vs_test/fcp_rv.pdf}
		%\caption{A subfigure}
		\label{fig:sub2}
	\end{subfigure}
	\caption{Firct Contentful Paint. First and Repeat View.}
	\label{figure:fcp_original_test}
\end{figure}

Figure \ref{figure:fcp_original_test}:
Similar as for PLT.
FV: more or less the same
RV: Test is slightly faster. This is because on test environment i can not control caching / cache-header settings of webserver. So more resources get cached automatically.



% add LCP / Speed Index ?




% -------------------------------------------------------------


\subsection{Test Website without GA vs Variant P1}

% use position 1 (top of head) is which is suggested by Google


\begin{figure}
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{plots/test_vs_position/plt_fv.pdf}
		%\caption{A subfigure}
		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{plots/test_vs_position/plt_rv.pdf}
		%\caption{A subfigure}
		\label{fig:sub2}
	\end{subfigure}
	\caption{Page Load Time. First and Repeat View.}
	\label{figure:plt_original_test}
\end{figure}



\begin{figure}
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{plots/test_vs_position/lcp_fv.pdf}
		%\caption{A subfigure}
		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{plots/test_vs_position/lcp_rv.pdf}
		%\caption{A subfigure}
		\label{fig:sub2}
	\end{subfigure}
	\caption{Largest Contentful Paint. First and Repeat View.}
	\label{figure:plt_original_test}
\end{figure}





% -------------------------------------------------------------

\subsection{IV Position: Variant P1 vs Variant P2 vs Variant P3}


% whats the impact of the position ?

TTFB:
- Repeat View is slower (on median)

% -------------------------------------------------------------


\subsection{IV Attribute: Variant A1 vs Variant A2 vs Variant A3}

% so does it really not matter ?

The GA measurements are median over all views, first view and repeat view.
Hence they are always the same for FV and RV.
With this setup, we do not have different data for RUM measurements from Google depending on if the website was loaded the first time or from cache.


CLS:
- medians are all the same
- 

% -------------------------------------------------------------

\subsection{IV Other Script: Variant OS1 vs Variant OS2}







% ----------------------------------------------------------------------------------------------------


\section{Other Aspects and Points of Discussion}


% For each attempt, describe: Threats to validity, generalizability


% -------------------------------------------------------------

\subsection{Generalizability}

% meine Daten zeige nur für Chrome, MacBook, diese Geschwindigkeit etc.
% Und auch nur für diese Test-Website
% Die Schwierigkeit der Generalisierbarkeit ist eines der grössten Probleme bei dieser Fragestellung




% -------------------------------------------------------------



\subsection{Internal and External Validity}



% The quality and quantity of the data needs to be discussed
% Quality: There are chances that some data are malformed, e.g. because internet connection was bad, etc.
% Quantity: Is the amount of data sufficient to make the evaluation generalisable



% 2016 Kohavi: Analysis of Experiments
















% ----------- To big to fail... to delete :/ -----------


% \subsection{Bulk Test Overview: Description of test result page}

% \begin{itemize}
% \item Each test has Test ID: YYMMDD\textunderscore random\textunderscore random
% \item Test results after bulk test available under \url{http://localhost:4000/result/{testID}/}
% \item For each test run, following data is available:
% 	\begin{itemize}
% 	\item Link to test results: Test result page as same as for single test run
% 	\item Median load time (First view)
% 	\item Median load time (Repeat view)
% 	\item Median Speed Index (First View)
% 	\item Raw page data (file: [TestID\textunderscore summary.csv]
% 	\item Raw object data (file: [TestID\textunderscore details.csv])
% 	\item Http archive (.har) (file: json)
% 	\end{itemize}
	
% \item Average First View Load Time
% \item Average Repeat View Load Time
% \item Combined Raw: Page Data  (file: [TestID\textunderscore summary.csv])
% \item Combined Raw: Object Data (file: [TestID\textunderscore details.csv]). For 100 test runs, this file is appr. 20 MB, 24432 rows, 76 columns. 
% \item Aggregate Statistics (file: [TestID\textunderscore aggregate.csv])
% \end{itemize}




% \subsection{Compare Section}

% WPT has a feature to compare multiple tests.
% Accessible under compare URL: \url{http://localhost:4000/video/compare.php?tests={TestID},{TestID},...}

% The compare page contains:

% \begin{itemize}
% \item Film strip
% \item Waterfall diagram
% \item Visual Progress diagram
% \item Timings diagram:
% 	\begin{itemize}
% 	\item Visually Complete (First View Visually Complete Median)
% 	\item Last Visual Change
% 	\item Load Time (onload)
% 	\item ...
% 	\end{itemize}
% \item Cumulative Layout Shift diagram
% \item Requests diagram
% \item Bytes diagram
% \item Visually complete
% \item Last Visual Change
% \item Load Time (onload)
% \item Load Time (Fully Loaded)
% \item DOM Content Loaded
% \item Speed Index
% \item Time to First Byte
% \item Time to Title
% \item Time to Start Render
% \item CPU Busy Time
% \item 85\% Visually Complete
% \item 90\% Visually Complete
% \item 95\% Visually Complete
% \item 99\% Visually Complete
% \item First Contentful Paint
% \item First Meaningful Paint
% \item Largest Contenful Paint
% \item Cumulative Layout Shift
% \item html Requests
% \item html Bytes
% \item js Requests
% \item js Bytes
% \item css Requests
% \item css Bytes
% \item image Requests
% \item image Bytes
% \item flash Requests
% \item flash Bytes
% \item font Requests
% \item font Bytes
% \item video Requests
% \item video Bytes
% \item other Requests
% \item other Bytes
% \end{itemize}




